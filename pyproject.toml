[build-system]
requires = ["setuptools>=65.0", "wheel"]
build-backend = "setuptools.build_meta"

[project]
name = "alpha-berkeley-framework"
version = "0.2.0"
description = "An open-source, domain-agnostic, capability-based architecture for building intelligent agents"
readme = "README.md"
requires-python = ">=3.11"
license = {text = "MIT"}
authors = [
    {name = "Thorsten Hellert", email = "thellert@lbl.gov"},
]
maintainers = [
    {name = "Thorsten Hellert", email = "thellert@lbl.gov"},
]
keywords = [
    "ai", "agents", "framework", "scientific-computing", "langgraph", 
    "epics", "accelerator-physics", "als", "berkeley", "agent-framework",
    "capability-based", "human-in-the-loop", "container-orchestration"
]
classifiers = [
    "Development Status :: 3 - Alpha",
    "Intended Audience :: Developers",
    "Intended Audience :: Science/Research",
    "License :: OSI Approved :: MIT License",
    "Operating System :: OS Independent",
    "Programming Language :: Python :: 3",
    "Programming Language :: Python :: 3.11",
    "Programming Language :: Python :: 3.12",
    "Topic :: Scientific/Engineering",
    "Topic :: Scientific/Engineering :: Physics",
    "Topic :: Software Development :: Libraries :: Python Modules",
    "Topic :: System :: Distributed Computing",
]

# Core runtime dependencies from requirements.txt analysis
dependencies = [
    # LangGraph dependencies - CRITICAL VERSION REQUIREMENTS
    "langgraph>=0.5.2",
    "langchain-core>=0.3.68",
    "langgraph-checkpoint-postgres>=2.0.22,<3.0.0",
    "langgraph-sdk>=0.1.70,<0.2.0",
    "psycopg[pool]>=3.1.0,<4.0.0",
    "psycopg-pool>=3.1.0,<4.0.0",
    "langchain-postgres>=0.0.12,<0.1.0",
    
    # Core framework dependencies
    "rich>=14.0.0",
    "pydantic-ai>=0.2.11",
    "python-dotenv>=1.1.0",
    "PyYAML>=6.0.2",
    "Jinja2>=3.1.6",
    "requests>=2.32.3",
    
    # Runtime dependencies discovered during testing
    "opentelemetry-api>=1.36.0",
    "opentelemetry-sdk>=1.36.0",
    "logfire>=3.16.1",
    "pure_eval>=0.2.3",
    "future>=1.0.0",
    "nest-asyncio>=1.6.0",
    
    # Container management (Podman, not Docker)
    "podman>=5.4.0",
    "podman-compose>=1.4.0",
    
    # Jupyter notebook support
    "nbformat>=5.0.0",
    "nbclient",
    
    # Networking and protocols
    "websocket-client>=1.7.0",
    "urllib3>=2.4.0",
    "certifi>=2025.4.26",
    "charset-normalizer>=3.4.2",
    "idna>=3.10",
    "MarkupSafe>=3.0.2",
]

[project.optional-dependencies]
# Documentation dependencies
docs = [
    "sphinx>=8.0.0",
    "pydata-sphinx-theme",
    "myst-parser",
    "sphinx-copybutton",
    "sphinx-autobuild",
    "sphinx-design",
    "sphinxcontrib-mermaid",
    "sphinxcontrib-jsmath>=1.0.1",
    "graphviz",
]

# Scientific computing stack
scientific = [
    "pandas>=2.2.3",
    "numpy>=2.2.6",
    "scipy>=1.15.3",
    "matplotlib>=3.10.3",
    "seaborn",
    "scikit-learn",
    "ipywidgets",
]

# ALS/EPICS specific dependencies
epics = [
    "pyepics>=3.5.0",
    "als-archiver-client>=1.0.3",
]

# AI/ML provider integrations
ai-providers = [
    "openai",
    "anthropic",
    "google-generativeai",
    "ollama>=0.5.1",
]

# Database and storage
databases = [
    "pymongo",
    "neo4j",
    "qdrant-client",
]

# Memory and vector storage
memory = [
    "mem0ai>=0.1.88",
    "vecs>=0.4.5",
]

# Development and testing
dev = [
    "pytest",
    "pytest-asyncio",
    "black",
    "isort",
    "mypy",
    "pre-commit",
    "ruff",
]

# Natural language processing
nlp = [
    "nltk>=3.8.1",
]

# Utilities
utils = [
    "unique-namer>=0.1.0",
]

# All optional dependencies for complete installation
all = [
    "alpha-berkeley-framework[docs,scientific,epics,ai-providers,databases,memory,dev,nlp,utils]"
]

[project.urls]
Homepage = "https://thellert.github.io/alpha_berkeley"
Documentation = "https://thellert.github.io/alpha_berkeley"
Repository = "https://github.com/thellert/alpha_berkeley"
Issues = "https://github.com/thellert/alpha_berkeley/issues"
Changelog = "https://github.com/thellert/alpha_berkeley/blob/main/CHANGELOG.md"

# Define console scripts for CLI entry points
[project.scripts]
alpha-berkeley = "interfaces.CLI.direct_conversation:main"
alpha-berkeley-deploy = "deployment.container_manager:main"
alpha-berkeley-docs = "docs.launch_docs:main"

# Package discovery configuration for src layout
[tool.setuptools.packages.find]
where = ["src"]
include = ["framework*", "configs*", "applications*"]

# Additional package discovery for interfaces and deployment
[tool.setuptools.packages]
"interfaces" = "interfaces"
"deployment" = "deployment"
"docs" = "docs"

# Include package data files
[tool.setuptools.package-data]
"*" = ["*.yml", "*.yaml", "*.json", "*.j2", "*.md", "*.txt", "*.cfg", "*.ini"]
"framework" = ["config.yml"]
"deployment" = ["*.py"]
"docs" = ["*.py", "Makefile", "*.md", "*.png", "*.log", "*.pid"]

# Development tool configurations
[tool.black]
line-length = 100
target-version = ['py311']
include = '\.pyi?$'
extend-exclude = '''
/(
  # Exclude auto-generated files
  build/
  | dist/
  | venv/
  | \.venv/
  | _agent_data/
  | \.git/
  | __pycache__/
  | \.pytest_cache/
  | \.mypy_cache/
)/
'''

[tool.isort]
profile = "black"
line_length = 100
multi_line_output = 3
include_trailing_comma = true
force_grid_wrap = 0
use_parentheses = true
ensure_newline_before_comments = true
src_paths = ["src", "interfaces", "deployment"]

[tool.mypy]
python_version = "3.11"
warn_return_any = true
warn_unused_configs = true
disallow_untyped_defs = false  # Gradual typing
ignore_missing_imports = true
exclude = [
    "build/",
    "dist/",
    "venv/",
    "_agent_data/",
    "__pycache__/",
]

# Specific modules to ignore due to optional dependencies
[[tool.mypy.overrides]]
module = [
    "openai.*",
    "anthropic.*",
    "google.*",
    "ollama.*",
    "pandas.*",
    "numpy.*",
    "matplotlib.*",
    "pyepics.*",
    "pymongo.*",
    "neo4j.*",
    "qdrant_client.*",
    "mem0.*",
    "langfuse.*",
    "langgraph.*",
    "langchain.*",
    "podman.*",
]
ignore_missing_imports = true

[tool.pytest.ini_options]
minversion = "6.0"
addopts = "-ra -q --tb=short"
testpaths = [
    "tests",
    "src/applications/*/tests",
    "services/framework/*/tests"
]
python_files = [
    "test_*.py",
    "*_test.py"
]
python_classes = ["Test*"]
python_functions = ["test_*"]
asyncio_mode = "auto"

# Ruff configuration for modern Python linting
[tool.ruff]
line-length = 100
target-version = "py311"
src = ["src", "interfaces", "deployment"]

[tool.ruff.lint]
select = [
    "E",  # pycodestyle errors
    "W",  # pycodestyle warnings
    "F",  # pyflakes
    "I",  # isort
    "B",  # flake8-bugbear
    "C4", # flake8-comprehensions
    "UP", # pyupgrade
]
ignore = [
    "E501",  # line too long, handled by black
    "B008",  # do not perform function calls in argument defaults
    "C901",  # too complex
]

[tool.ruff.lint.per-file-ignores]
"__init__.py" = ["F401"]  # Allow unused imports in __init__.py
"tests/*" = ["B011"]      # Allow assert False

[tool.ruff.lint.isort]
known-first-party = ["framework", "configs", "applications", "interfaces", "deployment"]

# Coverage configuration (if using pytest-cov)
[tool.coverage.run]
source = ["src", "interfaces", "deployment"]
omit = [
    "*/tests/*",
    "*/__pycache__/*",
    "*/.*",
    "build/*",
    "dist/*",
    "venv/*",
    "_agent_data/*",
]

[tool.coverage.report]
exclude_lines = [
    "pragma: no cover",
    "def __repr__",
    "if self.debug:",
    "if settings.DEBUG",
    "raise AssertionError",
    "raise NotImplementedError",
    "if 0:",
    "if __name__ == .__main__.:",
    "class .*\\bProtocol\\):",
    "@(abc\\.)?abstractmethod",
]
